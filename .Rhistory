test_data %>%
group_by(train_type, switch) %>%
summarise(mean = mean(setting_sticks),
sd = sd(setting_sticks),
var = var(setting_sticks))
test_results <- aov_ez("sub", "setting_slips", test_data, within = "switch",
between = c("train_type"),
fun_aggregate = mean)
print(summary(test_results))
sum_emm_int <- emmeans(test_results, c("train_type", "switch"))
sum_emm_int
test_data %>%
group_by(train_type, switch) %>%
summarise(mean = mean(setting_slips),
sd = sd(setting_slips),
var = var(setting_slips))
test_results <- aov_ez("sub", "general_errors", test_data, within = "switch",
between = c("train_type"),
fun_aggregate = mean)
print(summary(test_results))
sum_emm_int <- emmeans(test_results, c("train_type", "switch"))
sum_emm_int
test_data %>%
group_by(train_type, switch) %>%
summarise(mean = mean(general_errors),
sd = sd(general_errors),
var = var(general_errors))
# some helpful things
library(tidyverse)
library(GGally)
library(lme4)
library(lmerTest)
library(wesanderson)
# some helpful things
library(tidyverse)
library(GGally)
library(lme4)
library(lmerTest)
library(sjstats)
library(wesanderson)
View(test_data)
View(test_data_k4)
# some helpful things
library(tidyverse)
library(GGally)
library(lme4)
library(lmerTest)
library(sjstats)
library(wesanderson)
project_path <- '/Users/lydiabarnes/Documents/academe/projects/doors'
trial_data <- read_csv(file.path(project_path, 'res','exp_lt_trl.csv'), show_col_types = FALSE)
avg_data <- read_csv(file.path(project_path, 'res','exp_lt_avg.csv'), show_col_types = FALSE)
train_data <- trial_data %>%
group_by(sub, ses, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean) %>%
ungroup() %>%
select(!c(subses,context,switch)) %>%
filter(ses==2) %>%
select(sub, general_errors, context_changes, train_type) %>%
mutate(train_type = train_type-1) %>%
mutate(sub = factor(sub),
train_type = case_when(train_type==0~"infrequent_change",train_type==1~"frequent_change"),
train_type = factor(train_type))
test_data <- avg_data %>%
filter(ses == 3) %>%
filter(switch == 0) %>%
select(sub, transfer, accuracy, setting_errors, learned_setting_errors) %>%
mutate(sub = factor(sub),
transfer = case_when(transfer==1~"complete",transfer==2~"partial"),
transfer = factor(transfer)) %>%
pivot_wider(names_from=transfer, values_from=c(accuracy, setting_errors, learned_setting_errors))
data <- inner_join(train_data, test_data, by="sub")
k4_data <- read_csv(file.path(project_path, "res", "exp_lt_maggi-k4.csv"), show_col_types = FALSE)
k4_data <- k4_data %>%
rename(sub = sid) %>%
mutate(sub = factor(sub),
transfer = case_when(transfer==1~"complete",transfer==2~"partial"),
transfer = factor(transfer))
k4_data$k4_onset[k4_data$k4_onset == Inf] <- k4_data$nclicks[k4_data$k4_onset == Inf]
k4_data <- k4_data %>%
filter(ses == 3) %>%
select(sub, transfer, k4_onset) %>%
pivot_wider(names_from = transfer, values_from = k4_onset) %>%
rename(k4_complete = complete, k4_partial = partial)
data <- inner_join(data, k4_data, by="sub")
stereo_data <- read_csv(file.path(project_path,"res", "exp_lt_stereotypy.csv"), show_col_types = FALSE)
stereo_data <- stereo_data %>%
select(sub, context, reclicks) %>%
group_by(sub) %>%
summarise(reclicks = mean(reclicks)) %>%
mutate(sub = factor(sub))
data <- inner_join(data, stereo_data, by="sub")
train_data %>% ggplot(aes(x=context_changes, fill=train_type)) +
geom_density(alpha=0.7) +
scale_fill_manual(values = wes_palette("IsleofDogs1"))
data %>% ggplot(aes(x=reclicks, fill=train_type)) +
geom_density(alpha = 0.7) +
scale_fill_manual(values = wes_palette("IsleofDogs1"))
var_names <- c("general_errors","context_changes", "reclicks")
mhl.mat <- as.matrix(data %>% select(general_errors, context_changes, reclicks)) # turn the data into a matrix
mhl.cov <- cov(mhl.mat[,var_names]) # get the covariance
mhl.dist <- mahalanobis(mhl.mat[,var_names],
colMeans(mhl.mat[,var_names]), mhl.cov) # get mhl
hist(mhl.dist, breaks = 20, col=wes_palette("IsleofDogs1")[1]) #viz
sprintf("For a Mahalanobis to be less that .1 per cent likely to have occured by chance, given our degrees of feedom (%f), it has to be a value greater than %f", length(mhl.dist)-1, qchisq(.001, df=length(mhl.dist)-1))
apply(mhl.mat[,var_names], 2, var)
for_collin <- data.frame(mhl.mat[,var_names])
ggpairs(for_collin)
acc <- ggpairs(data %>% select(accuracy_complete, context_changes, reclicks))
acc
pacc <- ggpairs(data %>% select(accuracy_partial, context_changes, reclicks))
pacc
serr <- ggpairs(data %>% select(setting_errors_complete, context_changes, reclicks))
serr
pserr <- ggpairs(data %>% select(setting_errors_partial, context_changes, reclicks))
pserr
kfour <- ggpairs(data %>% select(k4_complete, context_changes, reclicks))
kfour
pkfour <- ggpairs(data %>% select(k4_partial, context_changes, reclicks))
pkfour
data <- data %>%
mutate(general_errors = scale(general_errors)[,1],
reclicks = scale(reclicks)[,1],
context_changes = scale(context_changes)[,1])
intercept_only <- lmer(accuracy_complete-accuracy_partial ~ 1 + (1|train_type),
data = data)
summary(intercept_only)
icc(intercept_only)
intercept_only <- lmer(accuracy_complete-accuracy_partial ~ 1 + (1|train_type),
data = data)
summary(intercept_only)
performance::icc(intercept_only)
# first level effects
model1 <- lmer(accuracy_complete-accuracy_partial ~ 1 + context_changes + reclicks + (1|train_type),
data = data)
summary(model1)
# first and second level effects
model2 <- lmer(accuracy_complete-accuracy_partial ~ 1 + context_changes + reclicks + cf + (1 | train_type), data=data)
View(data)
View(avg_data)
# some helpful things
library(tidyverse)
library(GGally)
library(lme4)
library(lmerTest)
library(sjstats)
library(wesanderson)
project_path <- '/Users/lydiabarnes/Documents/academe/projects/doors'
trial_data <- read_csv(file.path(project_path, 'res','exp_lt_trl.csv'), show_col_types = FALSE)
avg_data <- read_csv(file.path(project_path, 'res','exp_lt_avg.csv'), show_col_types = FALSE)
train_data <- trial_data %>%
group_by(sub, ses, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean) %>%
ungroup() %>%
select(!c(subses,context,switch)) %>%
filter(ses==2) %>%
select(sub, general_errors, context_changes, train_type) %>%
mutate(train_type = train_type-1) %>%
mutate(sub = factor(sub),
train_type = case_when(train_type==0~"infrequent_change",train_type==1~"frequent_change"),
train_type = factor(train_type))
test_data <- avg_data %>%
filter(ses == 3) %>%
filter(switch == 0) %>%
select(sub, transfer, full_transfer_first, accuracy, setting_errors, learned_setting_errors) %>%
mutate(sub = factor(sub),
transfer = case_when(transfer==1~"complete",transfer==2~"partial"),
transfer = factor(transfer),
full_transfer_first = factor(full_transfer_first)) %>%
rename(cf = full_transfer_first) %>%
pivot_wider(names_from=transfer, values_from=c(accuracy, setting_errors, learned_setting_errors))
data <- inner_join(train_data, test_data, by="sub")
k4_data <- read_csv(file.path(project_path, "res", "exp_lt_maggi-k4.csv"), show_col_types = FALSE)
k4_data <- k4_data %>%
rename(sub = sid) %>%
mutate(sub = factor(sub),
transfer = case_when(transfer==1~"complete",transfer==2~"partial"),
transfer = factor(transfer))
k4_data$k4_onset[k4_data$k4_onset == Inf] <- k4_data$nclicks[k4_data$k4_onset == Inf]
k4_data <- k4_data %>%
filter(ses == 3) %>%
select(sub, transfer, k4_onset) %>%
pivot_wider(names_from = transfer, values_from = k4_onset) %>%
rename(k4_complete = complete, k4_partial = partial)
data <- inner_join(data, k4_data, by="sub")
stereo_data <- read_csv(file.path(project_path,"res", "exp_lt_stereotypy.csv"), show_col_types = FALSE)
stereo_data <- stereo_data %>%
select(sub, context, reclicks) %>%
group_by(sub) %>%
summarise(reclicks = mean(reclicks)) %>%
mutate(sub = factor(sub))
data <- inner_join(data, stereo_data, by="sub")
train_data %>% ggplot(aes(x=context_changes, fill=train_type)) +
geom_density(alpha=0.7) +
scale_fill_manual(values = wes_palette("IsleofDogs1"))
data %>% ggplot(aes(x=reclicks, fill=train_type)) +
geom_density(alpha = 0.7) +
scale_fill_manual(values = wes_palette("IsleofDogs1"))
var_names <- c("general_errors","context_changes", "reclicks")
mhl.mat <- as.matrix(data %>% select(general_errors, context_changes, reclicks)) # turn the data into a matrix
mhl.cov <- cov(mhl.mat[,var_names]) # get the covariance
mhl.dist <- mahalanobis(mhl.mat[,var_names],
colMeans(mhl.mat[,var_names]), mhl.cov) # get mhl
hist(mhl.dist, breaks = 20, col=wes_palette("IsleofDogs1")[1]) #viz
sprintf("For a Mahalanobis to be less that .1 per cent likely to have occured by chance, given our degrees of feedom (%f), it has to be a value greater than %f", length(mhl.dist)-1, qchisq(.001, df=length(mhl.dist)-1))
apply(mhl.mat[,var_names], 2, var)
for_collin <- data.frame(mhl.mat[,var_names])
ggpairs(for_collin)
acc <- ggpairs(data %>% select(accuracy_complete, context_changes, reclicks))
acc
pacc <- ggpairs(data %>% select(accuracy_partial, context_changes, reclicks))
pacc
serr <- ggpairs(data %>% select(setting_errors_complete, context_changes, reclicks))
serr
pserr <- ggpairs(data %>% select(setting_errors_partial, context_changes, reclicks))
pserr
kfour <- ggpairs(data %>% select(k4_complete, context_changes, reclicks))
kfour
pkfour <- ggpairs(data %>% select(k4_partial, context_changes, reclicks))
pkfour
data <- data %>%
mutate(general_errors = scale(general_errors)[,1],
reclicks = scale(reclicks)[,1],
context_changes = scale(context_changes)[,1])
intercept_only <- lmer(accuracy_complete-accuracy_partial ~ 1 + (1|train_type),
data = data)
summary(intercept_only)
performance::icc(intercept_only)
# first level effects
model1 <- lmer(accuracy_complete-accuracy_partial ~ 1 + context_changes + reclicks + (1|train_type),
data = data)
summary(model1)
# first and second level effects
model2 <- lmer(accuracy_complete-accuracy_partial ~ 1 + context_changes + reclicks + cf + (1 | train_type), data=data)
summary(model2)
# first and second level effects with random slopes
model3 <- lmer(accuracy_complete-accuracy_partial ~ 1 + context_changes + reclicks + cf + (1 + context_changes + reclicks | train_type), data=data)
summary(model3)
# check whether both random slopes are worth including
ranova(model3)
output <- lm(accuracy_complete-accuracy_partial~context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete-accuracy_partial~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete-accuracy_partial~train_type*context_changes, data=data)
summary(output)
output <- lm(accuracy_complete-accuracy_partial~train_type*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete-accuracy_partial~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete-accuracy_partial~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete~context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete~train_type*context_changes, data=data)
summary(output)
output <- lm(accuracy_complete~train_type*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_partial~context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_partial~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_partial~train_type*context_changes, data=data)
summary(output)
output <- lm(accuracy_partial~train_type*reclicks, data=data)
summary(output)
output <- lm(accuracy_partial~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_partial~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete-setting_errors_partial~context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete-setting_errors_partial~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete-setting_errors_partial~train_type*context_changes, data=data)
summary(output)
output <- lm(setting_errors_complete-setting_errors_partial~train_type*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete-setting_errors_partial~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete-setting_errors_partial~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete~context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete~train_type*context_changes, data=data)
summary(output)
output <- lm(setting_errors_complete~train_type*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_complete~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_partial~context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_partial~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_partial~train_type*context_changes, data=data)
summary(output)
output <- lm(setting_errors_partial~train_type*reclicks, data=data)
summary(output)
output <- lm(setting_errors_partial~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(setting_errors_partial~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete-k4_partial~context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete-k4_partial~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete-k4_partial~train_type*context_changes, data=data)
summary(output)
output <- lm(k4_complete-k4_partial~train_type*reclicks, data=data)
summary(output)
output <- lm(k4_complete-k4_partial~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete-k4_partial~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete~context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete~train_type*context_changes, data=data)
summary(output)
output <- lm(k4_complete~train_type*reclicks, data=data)
summary(output)
output <- lm(k4_complete~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_complete~general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_partial~context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_partial~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_partial~train_type*context_changes, data=data)
summary(output)
output <- lm(k4_partial~train_type*reclicks, data=data)
summary(output)
output <- lm(k4_partial~train_type*general_errors*context_changes*reclicks, data=data)
summary(output)
output <- lm(k4_partial~general_errors*context_changes*reclicks, data=data)
summary(output)
intercept_only <- lmer(accuracy_complete ~ 1 + (1|train_type),
data = data)
summary(intercept_only)
performance::icc(intercept_only)
# first level effects
model1 <- lmer(accuracy_complete ~ 1 + context_changes + reclicks + (1|train_type),
data = data)
summary(model1)
# first and second level effects
model2 <- lmer(accuracy_complete ~ 1 + context_changes + reclicks + cf + (1 | train_type), data=data)
summary(model2)
# first and second level effects with random slopes
model3 <- lmer(accuracy_complete ~ 1 + context_changes + reclicks + cf + (1 + context_changes + reclicks | train_type), data=data)
summary(model3)
# check whether both random slopes are worth including
ranova(model3)
View(test_data)
View(test_data)
# https://www.rensvandeschoot.com/tutorials/lme4/
intercept_only <- lmer(accuracy_complete ~ 1 + (1|sub),
data = data)
View(data)
# https://www.rensvandeschoot.com/tutorials/lme4/
intercept_only <- lmer(accuracy_complete ~ 1 + (1|train_type),
data = data)
summary(intercept_only)
performance::icc(intercept_only)
# first level effects
model1 <- lmer(accuracy_complete ~ 1 + context_changes + reclicks + (1|train_type),
data = data)
summary(model1)
# first level effects, accounting for train phase errors
model2 <- lmer(accuracy_complete ~ 1 + context_changes + reclicks + general_errors + (1|train_type),
data=data)
summary(model2)
# first level effects with random slopes
model3 <- lmer(accuracy_complete ~ 1 + context_changes + reclicks + general_errors + (1 + context_changes + reclicks + general_errors | train_type),
data=data)
summary(model3)
# check whether all random slopes are worth including
ranova(model3)
output <- lm(accuracy_complete~context_changes*reclicks + (1|train_type), data=data)
output <- lm(accuracy_complete~train_type*context_changes*reclicks, data=data)
summary(output)
output <- lm(accuracy_complete~train_type*context_changes, data=data)
summary(output)
output <- lm(accuracy_complete~train_type*reclicks, data=data)
summary(output)
View(data)
rm(list=ls())
library(tidyverse)
source(file.path("src-dirich", "count_paths.R"))
source(file.path("src-dirich", "make_dirichlet.R"))
project_path <- getwd()
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# -------------------------------------------------------------------------
# load data
fnl <- file.path(project_path, "res", paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read.csv(fnl)
sid <- data$sub[1]
ctx <- data$context[1]
clicks <- data %>% filter(sub==sid,ses==2,context==ctx,door_cc==1,switch==0)
counts <- count_paths(clicks)
source(file.path("src-dirich", "count_paths.R"))
counts <- count_paths(clicks)
source(file.path("src-dirich", "count_paths.R"))
# loop through participants and contexts
routineness <- data.frame()
for (sid in unique(data$sub)){
print(sid)
for (ctx in unique(data$context)){
# get their train phase data, context-correct stay trial clicks only
clicks <- data %>% filter(sub==sid,ses==2,context==ctx,door_cc==1,switch==0)
counts <- count_paths(clicks)
tmp <- make_dirichlet(counts)
routineness <- rbind(routineness,cbind(sub=sid,context=ctx,train_type=unique(clicks$train_type),tmp))
}
}
# lydia barnes, september 2024
# reads and formats click data
# converts click data to count data for each of six possible paths
# generates dirichlet distribution from path count data
# extracts parameters and estimates entropy (our routineness measure)
rm(list=ls())
library(tidyverse)
source(file.path("src-dirich", "count_paths.R"))
source(file.path("src-dirich", "make_dirichlet.R"))
project_path <- getwd()
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# -------------------------------------------------------------------------
# load data
fnl <- file.path(project_path, "res", paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read.csv(fnl)
# -------------------------------------------------------------------------
# loop through participants and contexts
routineness <- data.frame()
for (sid in unique(data$sub)){
print(sprintf('subject %d', sid))
for (ctx in unique(data$context)){
# get their train phase data, context-correct stay trial clicks only
clicks <- data %>% filter(sub==sid,ses==2,context==ctx,door_cc==1,switch==0)
counts <- count_paths(clicks)
tmp <- make_dirichlet(counts)
routineness <- rbind(routineness,cbind(sub=sid,context=ctx,train_type=unique(clicks$train_type),tmp))
}
}
# lydia barnes, september 2024
# reads and formats click data
# converts click data to count data for each of six possible paths
# generates dirichlet distribution from path count data
# extracts parameters and estimates entropy (our routineness measure)
rm(list=ls())
library(tidyverse)
source(file.path("src-dirich", "count_paths.R"))
source(file.path("src-dirich", "make_dirichlet.R"))
project_path <- getwd()
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# -------------------------------------------------------------------------
# load data
fnl <- file.path(project_path, "res", paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read.csv(fnl)
# -------------------------------------------------------------------------
# loop through participants and contexts
routineness <- data.frame()
for (sid in unique(data$sub)){
print(sprintf('subject %d', sid))
for (ctx in unique(data$context)){
# get their train phase data, context-correct stay trial clicks only
clicks <- data %>% filter(sub==sid,ses==2,context==ctx,door_cc==1,switch==0)
counts <- count_paths(clicks)
tmp <- make_dirichlet(counts)
routineness <- rbind(routineness,cbind(sub=sid,context=ctx,train_type=unique(clicks$train_type),tmp))
}
}
# lydia barnes, september 2024
# reads and formats click data
# converts click data to count data for each of six possible paths
# generates dirichlet distribution from path count data
# extracts parameters and estimates entropy (our routineness measure)
rm(list=ls())
library(tidyverse)
source(file.path("src-dirich", "count_paths.R"))
source(file.path("src-dirich", "make_dirichlet.R"))
project_path <- getwd()
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# -------------------------------------------------------------------------
# load data
fnl <- file.path(project_path, "res", paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read.csv(fnl)
# -------------------------------------------------------------------------
# loop through participants and contexts
routineness <- data.frame()
for (sid in unique(data$sub)){
print(sprintf('subject %d', sid))
for (ctx in unique(data$context)){
# get their train phase data, context-correct stay trial clicks only
clicks <- data %>% filter(sub==sid,ses==2,context==ctx,door_cc==1,switch==0)
counts <- count_paths(clicks)
tmp <- make_dirichlet(counts)
routineness <- rbind(routineness,cbind(sub=sid,context=ctx,train_type=unique(clicks$train_type),tmp))
}
}
fnl <- file.path(project_path, "res", paste(paste(exp, "routines", sep = "_"), ".csv", sep = ""))
write_csv(routineness, fnl)
