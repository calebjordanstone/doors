doors <- unique(events$door)
View(transition_matrix)
View(events)
tr = 1
trial <- events %>% filter(t == tr)
View(trial)
if (nrow(trial) > 1) {
for (i in 2:nrow(trial)) {
door <- trial$door[i]
previous <- trial$door[i - 1]
transition_matrix[previous, which(doors==door)] <- transition_matrix[previous,which(doors==door)]+1
}
}
View(transition_matrix)
transition_matrix <- matrix(0, nrow = 16, ncol = 16)
for (tr in unique(events$t)) {
trial <- events %>% filter(t == tr)
# if there's more than one event, record door transitions
if (nrow(trial) > 1) {
for (i in 2:nrow(trial)) {
door <- trial$door[i]
previous <- trial$door[i - 1]
transition_matrix[previous, which(doors==door)] <- transition_matrix[previous,which(doors==door)]+1
}
}
}
which(doors==door)
door
transition_matrix <- matrix(0, nrow = 16, ncol = 16)
doors <- unique(events$door)
# select a trial
for (tr in unique(events$t)) {
trial <- events %>% filter(t == tr)
# if there's more than one event, record door transitions
if (nrow(trial) > 1) {
for (i in 2:nrow(trial)) {
door <- trial$door[i]
previous <- trial$door[i - 1]
transition_matrix[previous, door] <- transition_matrix[previous, door]+1
}
}
}
transition_counts <- colSums(as.matrix(transition_matrix > 0)+0)
transition_counts
transition_counts <- colSums(transition_matrix)
transition_counts
transition_counts[transition_counts!=0]
transition_counts <- mean(transition_counts[transition_counts!=0])
transition_counts
data.frame(transition_matrix)
colMax(data.frame(transition_matrix))
colSums(transition_matrix)
colMax(data.frame(transition_matrix))/colSums(transition_matrix)
transition_weights[!is.na(transition_weights)]
transition_weights <- colMax(data.frame(transition_matrix))/colSums(transition_matrix)
transition_weights[!is.na(transition_weights)]
colMax(transition_matrix)
transition_weights <- colMax(data.frame(transition_matrix))/colSums(transition_matrix)
transition_weights <- mean(transition_weights[!is.na(transition_weights)])
transition_weights
x <- data.frame(transition_matrix)
View(x)
sum(x)
x/sum(x)
entropy <- sapply(data.frame(transition_matrix),function(x){x/sum(x)})
entropy
transition_matrix/sum(transition_matrix)
entropy <- transition_matrix/sum(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
entropy
colSums(entropy,na.rm=TRUE)
-colSums(entropy,na.rm=TRUE)
mean(entropy,na.rm=TRUE)
entropy <- sapply(data.frame(transition_matrix),function(x){x/sum(x)})
entropy <- entropy * sapply(entropy,log2)
entropy <- -mean(entropy,na.rm=TRUE)
entropy
entropy <- transition_matrix/sum(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
entropy <- -mean(entropy,na.rm=TRUE)
entropy
entropy <- transition_matrix/sum(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
entropy[!is.na(entropy)]
x <- transition_matrix/sum(transition_matrix)
sum(x)
entropy <- transition_matrix/sum(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
entropy <- mean(-colSums(entropy,na.rm=TRUE))
entropy
entropy <- transition_matrix/sum(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
colSums(entropy,na.rm=TRUE)
entropy <- transition_matrix/sum(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
entropy <- -mean(entropy,na.rm=TRUE)
entropy
# lydia barnes, may 2024 counts, clusters, and/or traces stereotypical behaviour during training to
# explain performance at test
# NB: people can get an imperfect match score for the optimal path but an overshoot of zero if they double-click.
#--------------------------------------------------------------------------------------------------
# sources
library(tidyverse)
library(gtools)
source(file.path(getwd(), "src-stereo", "count_stereo.R"))
# settings
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# paths
project_path <- getwd()
data_path <- file.path(project_path, "res")
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
#--------------------------------------------------------------------------------------------------
# load event data
fnl <- file.path(data_path, paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read_csv(fnl, show_col_types = FALSE)
data <- data %>% filter(ses == 2)
if(exp=="exp_lt"){
# rm sub-62, who happened to have a very low rate of switches into context 1 during training sub-session 2
data <- data %>% filter(sub!=62)
}
# load shortest path data
fnl <- file.path(data_path, paste(paste(exp, "opt-path", sep = "_"), ".csv", sep = ""))
opt <- read_csv(fnl, show_col_types = FALSE)
# load graph of distances between doors
fnl <- file.path(project_path, "src-stereo", "graph.csv")
graph <- unname(data.matrix(read_csv(fnl, col_names = FALSE, show_col_types = FALSE)))
#--------------------------------------------------------------------------------------------------
# extract stereotypy metrics
stereo <- count_stereo(exp, data, opt, graph)
# save to file
fnl <- file.path(project_path, "res", paste(paste(exp, "stereotypy", sep = "_"), ".csv", sep = ""))
write_csv(stereo, fnl)
# lydia barnes, may 2024 counts, clusters, and/or traces stereotypical behaviour during training to
# explain performance at test
# NB: people can get an imperfect match score for the optimal path but an overshoot of zero if they double-click.
#--------------------------------------------------------------------------------------------------
# sources
library(tidyverse)
library(gtools)
source(file.path(getwd(), "src-stereo", "count_stereo.R"))
# settings
exp <- "exp_lt" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# paths
project_path <- getwd()
data_path <- file.path(project_path, "res")
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
#--------------------------------------------------------------------------------------------------
# load event data
fnl <- file.path(data_path, paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read_csv(fnl, show_col_types = FALSE)
data <- data %>% filter(ses == 2)
if(exp=="exp_lt"){
# rm sub-62, who happened to have a very low rate of switches into context 1 during training sub-session 2
data <- data %>% filter(sub!=62)
}
# load shortest path data
fnl <- file.path(data_path, paste(paste(exp, "opt-path", sep = "_"), ".csv", sep = ""))
opt <- read_csv(fnl, show_col_types = FALSE)
# load graph of distances between doors
fnl <- file.path(project_path, "src-stereo", "graph.csv")
graph <- unname(data.matrix(read_csv(fnl, col_names = FALSE, show_col_types = FALSE)))
#--------------------------------------------------------------------------------------------------
# extract stereotypy metrics
stereo <- count_stereo(exp, data, opt, graph)
# save to file
fnl <- file.path(project_path, "res", paste(paste(exp, "stereotypy", sep = "_"), ".csv", sep = ""))
write_csv(stereo, fnl)
library(tidyverse)
library(zeallot) #unpack/destructure with %<-%
grp_data <- read_csv("/Users/lydiabarnes/Documents/projects/doors/res/exp_ts_evt.csv")
grp_data <- read_csv("/Users/lydiabarnes/Documents/academe/projects/doors/res/exp_ts_evt.csv")
version <- "study-01" # pilot-data-00 (train and test), pilot-data-01 (learn and train), pilot-data-02 (learn and train, learn phase split into two parts)
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
sess <- c("ses-learn","ses-train","ses-test") # session: 'ses-learn','ses-train','ses-test'. can select one (e.g. ses <- c('ses-learn')) or multiple (e.g. ses <- c('ses-train','ses-test'))
# !if you open the project thru doors.Rproj, your working directory will automatically be the
# project path
project_path <- getwd()
res <- grp_data %>%
group_by(sub, ses, subses, t, context, train_type, transfer, full_transfer_first, original_house) %>%
summarise(
switch = max(switch), n_clicks = n(), n_cc = sum(door_cc), n_oc = sum(door_oc), n_lc = sum(door_lc), n_nc = sum(door_nc),
setting_sticks = select_oc[1],
setting_slips = max(select_oc_late),
context_changes = sum(select_cc)+sum(select_oc),
accuracy = n_cc / n_clicks,
general_errors = n_nc / n_clicks,
setting_errors = n_oc / n_clicks,
learned_setting_errors = n_lc / n_clicks
)
res$context_changes[intersect(which(res$switch==1),which(res$ses==2))] <- res$context_changes[intersect(which(res$switch==1),which(res$ses==2))]-1
rt <- grp_data %>%
group_by(sub, ses, subses, t, context, train_type, transfer) %>%
filter(door_cc == 1) %>%
summarise(rt = min(off)) # time to first correct click offset
res$rt <- rt$rt
res$win <- 4-res$n_clicks >= 0
fnl <- file.path(project_path, "res", paste(paste(exp, "trl", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
res <- res %>%
group_by(sub, ses, subses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
res <- res %>% select(!t)
fnl <- file.path(project_path, "res", paste(paste(exp, "avg-ss", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
res <- res %>%
group_by(sub, ses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
res <- res %>% select(!subses)
fnl <- file.path(project_path, "res", paste(paste(exp, "avg", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
grp_data <- read_csv("/Users/lydiabarnes/Documents/academe/projects/doors/res/exp_lt_evt.csv")
exp <- "exp_lt"
res <- grp_data %>%
group_by(sub, ses, subses, t, context, train_type, transfer, full_transfer_first, original_house) %>%
summarise(
switch = max(switch), n_clicks = n(), n_cc = sum(door_cc), n_oc = sum(door_oc), n_lc = sum(door_lc), n_nc = sum(door_nc),
setting_sticks = select_oc[1],
setting_slips = max(select_oc_late),
context_changes = sum(select_cc)+sum(select_oc),
accuracy = n_cc / n_clicks,
general_errors = n_nc / n_clicks,
setting_errors = n_oc / n_clicks,
learned_setting_errors = n_lc / n_clicks
)
res$context_changes[intersect(which(res$switch==1),which(res$ses==2))] <- res$context_changes[intersect(which(res$switch==1),which(res$ses==2))]-1
rt <- grp_data %>%
group_by(sub, ses, subses, t, context, train_type, transfer) %>%
filter(door_cc == 1) %>%
summarise(rt = min(off)) # time to first correct click offset
res$rt <- rt$rt
res$win <- 4-res$n_clicks >= 0
fnl <- file.path(project_path, "res", paste(paste(exp, "trl", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
res <- res %>%
group_by(sub, ses, subses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
source(file.path("src","get_transition_probabilities.R"))
# by subject
#   grouping by subsession
res <- res %>%
group_by(sub, ses, subses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
res <- res %>% select(!t)
fnl <- file.path(project_path, "res", paste(paste(exp, "avg-ss", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
res <- res %>%
group_by(sub, ses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
res <- res %>% select(!subses)
fnl <- file.path(project_path, "res", paste(paste(exp, "avg", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
# lydia barnes, may 2024 counts, clusters, and/or traces stereotypical behaviour during training to
# explain performance at test
# NB: people can get an imperfect match score for the optimal path but an overshoot of zero if they double-click.
#--------------------------------------------------------------------------------------------------
# sources
library(tidyverse)
library(gtools)
source(file.path(getwd(), "src-stereo", "count_stereo.R"))
# settings
exp <- "exp_lt" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# paths
project_path <- getwd()
data_path <- file.path(project_path, "res")
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
#--------------------------------------------------------------------------------------------------
# load event data
fnl <- file.path(data_path, paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read_csv(fnl, show_col_types = FALSE)
data <- data %>% filter(ses == 2)
if(exp=="exp_lt"){
# rm sub-62, who happened to have a very low rate of switches into context 1 during training sub-session 2
data <- data %>% filter(sub!=62)
}
# load shortest path data
fnl <- file.path(data_path, paste(paste(exp, "opt-path", sep = "_"), ".csv", sep = ""))
opt <- read_csv(fnl, show_col_types = FALSE)
# load graph of distances between doors
fnl <- file.path(project_path, "src-stereo", "graph.csv")
graph <- unname(data.matrix(read_csv(fnl, col_names = FALSE, show_col_types = FALSE)))
#--------------------------------------------------------------------------------------------------
# extract stereotypy metrics
stereo <- count_stereo(exp, data, opt, graph)
# save to file
fnl <- file.path(project_path, "res", paste(paste(exp, "stereotypy", sep = "_"), ".csv", sep = ""))
write_csv(stereo, fnl)
# lydia barnes, may 2024 counts, clusters, and/or traces stereotypical behaviour during training to
# explain performance at test
# NB: people can get an imperfect match score for the optimal path but an overshoot of zero if they double-click.
#--------------------------------------------------------------------------------------------------
# sources
library(tidyverse)
library(gtools)
source(file.path(getwd(), "src-stereo", "count_stereo.R"))
# settings
exp <- "exp_lt" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# paths
project_path <- getwd()
data_path <- file.path(project_path, "res")
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
#--------------------------------------------------------------------------------------------------
# load event data
fnl <- file.path(data_path, paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read_csv(fnl, show_col_types = FALSE)
data <- data %>% filter(ses == 2)
if(exp=="exp_lt"){
# rm sub-62, who happened to have a very low rate of switches into context 1 during training sub-session 2
data <- data %>% filter(sub!=62)
}
# load shortest path data
fnl <- file.path(data_path, paste(paste(exp, "opt-path", sep = "_"), ".csv", sep = ""))
opt <- read_csv(fnl, show_col_types = FALSE)
# load graph of distances between doors
fnl <- file.path(project_path, "src-stereo", "graph.csv")
graph <- unname(data.matrix(read_csv(fnl, col_names = FALSE, show_col_types = FALSE)))
#--------------------------------------------------------------------------------------------------
# extract stereotypy metrics
stereo <- count_stereo(exp, data, opt, graph)
# save to file
fnl <- file.path(project_path, "res", paste(paste(exp, "stereotypy", sep = "_"), ".csv", sep = ""))
write_csv(stereo, fnl)
# lydia barnes, may 2024 counts, clusters, and/or traces stereotypical behaviour during training to
# explain performance at test
# NB: people can get an imperfect match score for the optimal path but an overshoot of zero if they double-click.
#--------------------------------------------------------------------------------------------------
# sources
library(tidyverse)
library(gtools)
source(file.path(getwd(), "src-stereo", "count_stereo.R"))
# settings
exp <- "exp_lt" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
# paths
project_path <- getwd()
data_path <- file.path(project_path, "res")
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
#--------------------------------------------------------------------------------------------------
# load event data
fnl <- file.path(data_path, paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
data <- read_csv(fnl, show_col_types = FALSE)
data <- data %>% filter(ses == 2)
if(exp=="exp_lt"){
# rm sub-62, who happened to have a very low rate of switches into context 1 during training sub-session 2
data <- data %>% filter(sub==62)
}
# load shortest path data
fnl <- file.path(data_path, paste(paste(exp, "opt-path", sep = "_"), ".csv", sep = ""))
opt <- read_csv(fnl, show_col_types = FALSE)
# load graph of distances between doors
fnl <- file.path(project_path, "src-stereo", "graph.csv")
graph <- unname(data.matrix(read_csv(fnl, col_names = FALSE, show_col_types = FALSE)))
utils::globalVariables(".data")
### insensitive to feedback?  count re-clicks on previous context doors on switch trials
events <- data %>%
filter(switch == 1, door_oc == 1)
reclicks <- events %>%
group_by(sub, ses, t, context, subses) %>%
summarise(n = n(), n_reclicks = n() - length(unique(door)))
reclicks <- reclicks %>%
group_by(sub, ses, context, subses) %>%
summarise(clicks = mean(n), reclicks = mean(n_reclicks))
events <- data %>%
filter(switch == 0)
accuracy <- events %>%
group_by(sub, ses, t, context, subses) %>%
summarise(n_clicks = n(), n_correct = sum(door_cc), n_correct_oc = sum(door_oc),
accuracy = n_correct / n_clicks, metatask_accuracy = (n_correct+n_correct_oc)/n_clicks)
accuracy <- accuracy %>%
group_by(sub, ses, context, subses) %>%
summarise(accuracy = mean(accuracy), metatask_accuracy = mean(metatask_accuracy))
transitions <- data.frame(
sub = integer(), ses = integer(), context = integer(), subses = integer(),
transition_counts = double(), transition_weights = double(), entropy = double()
)
print("getting the transition matrix")
for (su in unique(data$sub)) {
print(su)
for (se in unique(data$ses)) {
for (co in unique(data$context)) {
for (ss in unique(data$subses)) {
# reduce to correct click events on stay trials
events <- data %>% filter(switch == 0, sub == su, ses == se, context == co, subses == ss)
# -------------------------------------------------------------------------
# make the full transitions matrix
transition_matrix <- matrix(0, nrow = 16, ncol = 16)
doors <- unique(events$door)
# select a trial
for (tr in unique(events$t)) {
trial <- events %>% filter(t == tr)
# if there's more than one event, record door transitions
if (nrow(trial) > 1) {
for (i in 2:nrow(trial)) {
door <- trial$door[i]
previous <- trial$door[i - 1]
transition_matrix[previous, door] <- transition_matrix[previous, door]+1
}
}
}
# -------------------------------------------------------------------------
# TRANSITION COUNTS
# for each door i, find the number of unique ways that this person gets to it, then take the mean across i's
transition_counts <- colSums(transition_matrix)
transition_counts <- mean(transition_counts[transition_counts!=0])
# -------------------------------------------------------------------------
# TRANSITION WEIGHTS
# for each door i, find the door j that most often goes to it. take its probability (n clicks on j before i / n clicks on i)
transition_weights <- colMax(data.frame(transition_matrix))/colSums(transition_matrix)
transition_weights <- mean(transition_weights[!is.na(transition_weights)])
# -------------------------------------------------------------------------
# ENTROPY
# take the probability of each transition, given the number of transitions
# multiply by the log of its probability, sum log probabilities, and take the negative
entropy <- transition_matrix/colSums(transition_matrix)
entropy <- entropy * sapply(entropy,log2)
entropy <- -colSums(entropy,na.rm=TRUE)
entropy <- mean(entropy)
if (!is.nan(transition_counts)) {
# store
transitions[nrow(transitions) + 1, ] <- data.frame(su, se, co, ss, transition_counts, transition_weights, entropy)
}
}
}
}
}
transitions_accuracy <- accuracy %>% add_column(transition_counts = transitions$transition_counts,
transition_weights = transitions$transition_weights,
entropy = transitions$entropy)
path_match <- data.frame(
sub = integer(), ses = integer(), t = integer(), context = integer(), subses = integer(), travelled = double(),
travelling_match = double(), travelling_overshoot = double(), hamiltonian_match = double(), hamiltonian_overshoot = double()
)
print("processing match to shortest path")
for (su in unique(data$sub)) {
print(su)
for (se in c(2)) {
for (co in unique(data$context)) {
for (ss in unique(data$subses)) {
# get clicks on stay trials
events <- data %>% filter(switch == 0, sub == su, ses == se, context == co, door_cc == 1, subses == ss)
# make the data frame
tmp <- data.frame(sub = integer(), ses = integer(), t = integer(), context = integer(), subses = integer())
for (tr in unique(events$t)) {
tmp[nrow(tmp) + 1, ] <- data.frame(su, se, tr, co, ss)
}
### travelling salesman solutions (return to start)
opt_sub <- opt %>% filter(sub == su, context == co, algorithm == "travelling")
df <- compare_paths(graph, events, opt_sub, "travelling")
df_tsp <- df %>% rename(travelling_match = match, travelling_overshoot = overshoot)
### shortest hamiltonian path (don't return to start)
opt_sub <- opt %>% filter(sub == su, context == co, algorithm == "hamiltonian")
df <- compare_paths(graph, events, opt_sub, "hamiltonian")
df_hp <- df %>% rename(hamiltonian_match = match, hamiltonian_overshoot = overshoot) %>% select(hamiltonian_match,hamiltonian_overshoot)
# stack
tmp <- cbind(tmp, df_tsp, df_hp)
path_match <- rbind(path_match, tmp)
}
}
}
}
path_match %>%
group_by(sub, ses, context, subses) %>%
summarise_all(mean) %>% select(!t)
path_match <- path_match %>%
group_by(sub, ses, context, subses) %>%
summarise_all(mean) %>% select(!t)
t <- transitions_accuracy %>%
ungroup() %>%
select(accuracy, metatask_accuracy, transition_counts, transition_weights, entropy)
r <- reclicks %>%
ungroup() %>%
select(clicks, reclicks)
stereo <- bind_cols(path_match, t, r)
events <- data %>%
filter(switch == 1, door_oc == 1)
reclicks <- events %>%
group_by(sub, ses, t, context, subses) %>%
summarise(n = n(), n_reclicks = n() - length(unique(door)))
View(reclicks)
events <- data %>%
filter(switch == 1, door_oc == 1)
reclicks <- events %>%
group_by(sub, ses, t, context, subses)
View(events)
