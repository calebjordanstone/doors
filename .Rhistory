# by subject
#   grouping by subsession
res <- res %>%
group_by(sub, ses, subses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
fnl <- file.path(project_path, "res", paste(paste(exp, "avg-ss", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
#   just grouping by session
res <- res %>%
group_by(sub, ses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
fnl <- file.path(project_path, "res", paste(paste(exp, "avg", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
? select
# lydia barnes, may 2024
# applies maggi algorithm. algorithm estimates probability of using a given strategy, weighting by recency.
library(zeallot) #unpack/destructure with %<-%
library(tidyverse)
source(file.path(getwd(), "src-learn", "get_maggi.R"))
source(file.path(getwd(), "src-learn", "format_data_for_maggi.R"))
source(file.path(getwd(), "src", "get_subs.R"))
set.seed(17)
simulation <- FALSE
if (simulation){
# synthesise data
ps <- c(.1, .3, .6, .9) #reasonable steps in the probability of successes over runs of trials
n <- 25 #trials per run
data <- unlist(lapply(ps, rbinom, n=n, size=1)) # n * length(ps) trials drawn from a binomial distribution
c(alphas,betas,beta_map,beta_variance) %<-% get_maggi(data)
# view the final beta distribution
increments <- seq(0,1,by=.01)
plot(increments,dbeta(increments,alphas[length(data)],betas[length(data)]),type="l",col="darkgreen")
}else{
# read real data
project_path <- getwd()
# settings ----------------------------------------------------------------
version <- "study-01"
exp <- "exp_lt" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
sess <- c(1,3) # session: 1 = 'ses-learn', 2 = 'ses-train', 3 = 'ses-test'.
conditions <- c(1,2) # if ses = 3: 1 = complete transfer, 2 = partial transfer. if ses = 1: 1 = context 1, 2 = context 2
colours <- c("darkgreen","limegreen","gold","orange")
save_plots <- FALSE
subs <- get_subs(exp, version)
events <- read.csv(file.path('res',paste(paste(exp, "evt", sep='_'), ".csv", sep='')))
group_data <- data.frame(
sub = integer(), ses = integer(), context = integer(), train_type = integer(), transfer = integer(), event = integer(),
k1 = numeric(), k2 = numeric(), k3 = numeric(), k4 = numeric(), win = integer(), stable_k4 = integer()
)
session_names <- c('ses-learn','ses-train','ses-test')
for (subject in subs){
print(subject)
sid <- as.numeric(substring(subject,5,7))
train_type <- events %>% filter(sub==sid, ses==2) %>% pull(train_type)
train_type <- train_type[[1]]
for (ses in sess){
if(subject=="sub-64"){
print("skipping missing data")
}else{
for (condition in conditions){
if (ses < 3){
condition_names <- c("context-1","context-2")
context <- condition
transfer <- NA
}else{
condition_names <- c("full-transfer","partial-transfer")
context <- NA
transfer <- condition
}
# evidence ----------------------------------------------------------------
strategies <- format_data_for_maggi(exp,nsub=sid,nses=ses,ncontext=condition,method="by_event",specific_doors=FALSE,competitive=TRUE,evaluate_all=FALSE)
# empty figure ------------------------------------------------------------
if (save_plots){
fnl <- file.path(project_path,'fig',paste(paste(exp, subject, session_names[ses], condition_names[condition], "maggi", sep = "_"), ".png", sep = ""))
png(file = fnl)
plot(1:nrow(strategies),rep(0,1,nrow(strategies)),type="l",col="black",ylim=c(0,1))
}
# maggi -------------------------------------------------------------------
i <- 0
beta_maps <- matrix(NA,4,nrow(strategies))
for (strategy in names(strategies)[2:length(names(strategies))]){
i <- i+1
strategy <- strategies %>% pull(strategy)
# calculate recency-weighted probability of finding strategy s
c(alphas,betas,beta_map,beta_variance) %<-% get_maggi(strategy)
# store data
beta_maps[i,1:ncol(beta_maps)] <- beta_map
if (save_plots){
# view alphas and betas over time
points(1:length(strategy),beta_map,type="l",col=colours[i])
}
}
if (save_plots){
dev.off()
}
# format the data
data <- data.frame(sub = integer(), ses = integer(), context = integer(), train_type = integer(), transfer = integer(), event = integer(), k1 = numeric(), k2 = numeric(), k3 = numeric(), k4 = numeric(), win = integer())
for (event in 1:length(beta_map)){
win <- which(beta_maps[1:nrow(beta_maps),event] == max(beta_maps[1:nrow(beta_maps),event]))
if (sum(beta_maps[1:nrow(beta_maps),event])==0){win <- NA}
tmp <- data.frame(sid, ses, context, transfer, train_type, event, k1 = beta_maps[1,event], k2 = beta_maps[2,event], k3 = beta_maps[3,event], k4 = beta_maps[4,event], win)
data <- rbind(data,tmp)
}
last_strategy_change <- max(which(diff(data$win)!=0))+1
data <- data %>%
mutate(stable_k4 = case_when(event < last_strategy_change ~ 0, event %in% intersect(which(event >= last_strategy_change), which(win == 4)) ~ 1, .default = NA))
group_data <- rbind(group_data,data)
}
}
}
}
# threshold ---------------------------------------------------------------
results <- group_data %>% group_by(sid,ses,context,train_type,transfer) %>% summarise(nclicks = n(),k4_onset = min(which(stable_k4==1)))
}
write.csv(group_data,file.path('res',paste(paste(exp,'maggi-map',sep='_'),'csv', sep='.')))
write.csv(results,file.path('res',paste(paste(exp,'maggi-k4',sep='_'),'csv', sep='.')))
results_wide <- results %>% filter(ses==1) %>% rename(k4_learn=k4_onset)
results_wide$k4_test <- results %>% filter(ses==3) %>% pull(k4_onset)
# lydia barnes, march 2024 this script extracts, formats, and summarises data from the 'doors'
# project.
### sources
library(tidyverse)
library(zeallot) #unpack/destructure with %<-%
source(file.path("src", "get_subs.R"))
source(file.path("src", "get_switch.R"))
source(file.path("src", "get_data.R"))
source(file.path("src","get_setting_stability.R"))
source(file.path("src","get_transition_probabilities.R"))
source(file.path("src","get_learned_doors.R"))
### settings
# !you will want to update these settings a lot during piloting, when the task code or the way you
# test changes, or when you test participants on different subsets of the task phases
version <- "study-01" # pilot-data-00 (train and test), pilot-data-01 (learn and train), pilot-data-02 (learn and train, learn phase split into two parts)
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
sess <- c("ses-learn","ses-train","ses-test") # session: 'ses-learn','ses-train','ses-test'. can select one (e.g. ses <- c('ses-learn')) or multiple (e.g. ses <- c('ses-train','ses-test'))
### paths
# !if you open the project thru doors.Rproj, your working directory will automatically be the
# project path
project_path <- getwd()
if (!dir.exists(file.path(project_path, "res"))) {
# check that the results directory exists. if it doesn't, create it.
dir.create(file.path(project_path, "res"))
}
# !you will need to change the data path to match the location of OneDrive on your personal
# computer
data_path <- file.path("/Users/lydiabarnes/OneDrive - UNSW/task switch and transfer/data-sandpit", version)
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
### load an up-to-date list of participants
subs <- get_subs(exp, version)
### extract events from the raw data
# make an empty data frame with all the variables (columns) that we will want
grp_data <- data.frame(
sub = integer(), ses = integer(), subses = integer(), t = integer(), context = integer(), door = integer(),
door_cc = integer(), door_oc = integer(), on = numeric(), off = numeric(),
switch = integer(), train_type = integer(), transfer = integer(), full_transfer_first = integer(),
original_house = integer()
)
# for each subject and session, use the function 'get_data' to load their raw data and attach it to
# our 'grp_data' data frame with one measurement (row) per event (click or hover)
for (sub in subs) {
print(sub)
sid <- as.numeric(substring(sub,5,7))
for (ses in sess) {
train_type <- NA
context_one_doors <- NA
if (sub=="sub-64" && ses=="ses-learn"){
print("skipping missing data")
}else{
if (ses == "ses-test") {
train_type <- grp_data %>%
filter(sub == sid, ses == 2) %>%
select(train_type) %>%
unique() %>%
pull()
train_doors <- grp_data %>%
filter(sub==sid,ses==ses,door_cc==1) %>%
select(door,context) %>%
unique()
}
data <- get_data(data_path, exp, sub, ses, train_type, train_doors) # load and format raw data
grp_data <- rbind(grp_data, data) # add to the 'grp_data' data frame so we end up with all subjects and sessions in one spreadsheet
}
}
}
# track whether context-incorrect clicks in the test phase land on doors that were learned in the train phase
if(exp=="exp_lt"){
door_lc <- get_learned_doors(grp_data)
grp_data <- grp_data %>% add_column(door_lc = door_lc, .after="door_oc")
}else{
grp_data <- grp_data %>% mutate(door_lc = c(kronecker(matrix(1, nrow(res), 1), NA)), .after="door_oc")
}
# lydia barnes, may 2024
# applies maggi algorithm. algorithm estimates probability of using a given strategy, weighting by recency.
library(zeallot) #unpack/destructure with %<-%
library(tidyverse)
source(file.path(getwd(), "src-learn", "get_maggi.R"))
source(file.path(getwd(), "src-learn", "format_data_for_maggi.R"))
source(file.path(getwd(), "src", "get_subs.R"))
set.seed(17)
simulation <- FALSE
if (simulation){
# synthesise data
ps <- c(.1, .3, .6, .9) #reasonable steps in the probability of successes over runs of trials
n <- 25 #trials per run
data <- unlist(lapply(ps, rbinom, n=n, size=1)) # n * length(ps) trials drawn from a binomial distribution
c(alphas,betas,beta_map,beta_variance) %<-% get_maggi(data)
# view the final beta distribution
increments <- seq(0,1,by=.01)
plot(increments,dbeta(increments,alphas[length(data)],betas[length(data)]),type="l",col="darkgreen")
}else{
# read real data
project_path <- getwd()
# settings ----------------------------------------------------------------
version <- "study-01"
exp <- "exp_lt" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
sess <- c(1,3) # session: 1 = 'ses-learn', 2 = 'ses-train', 3 = 'ses-test'.
conditions <- c(1,2) # if ses = 3: 1 = complete transfer, 2 = partial transfer. if ses = 1: 1 = context 1, 2 = context 2
colours <- c("darkgreen","limegreen","gold","orange")
save_plots <- FALSE
subs <- get_subs(exp, version)
events <- read.csv(file.path('res',paste(paste(exp, "evt", sep='_'), ".csv", sep='')))
group_data <- data.frame(
sub = integer(), ses = integer(), context = integer(), train_type = integer(), transfer = integer(), event = integer(),
k1 = numeric(), k2 = numeric(), k3 = numeric(), k4 = numeric(), win = integer(), stable_k4 = integer()
)
session_names <- c('ses-learn','ses-train','ses-test')
for (subject in subs){
print(subject)
sid <- as.numeric(substring(subject,5,7))
train_type <- events %>% filter(sub==sid, ses==2) %>% pull(train_type)
train_type <- train_type[[1]]
for (ses in sess){
if(exp=="exp_lt" && ses==1 && subject=="sub-64"){
print("skipping missing data")
}else{
for (condition in conditions){
if (ses < 3){
condition_names <- c("context-1","context-2")
context <- condition
transfer <- NA
}else{
condition_names <- c("full-transfer","partial-transfer")
context <- NA
transfer <- condition
}
# evidence ----------------------------------------------------------------
strategies <- format_data_for_maggi(exp,nsub=sid,nses=ses,ncontext=condition,method="by_event",specific_doors=FALSE,competitive=TRUE,evaluate_all=FALSE)
# empty figure ------------------------------------------------------------
if (save_plots){
fnl <- file.path(project_path,'fig',paste(paste(exp, subject, session_names[ses], condition_names[condition], "maggi", sep = "_"), ".png", sep = ""))
png(file = fnl)
plot(1:nrow(strategies),rep(0,1,nrow(strategies)),type="l",col="black",ylim=c(0,1))
}
# maggi -------------------------------------------------------------------
i <- 0
beta_maps <- matrix(NA,4,nrow(strategies))
for (strategy in names(strategies)[2:length(names(strategies))]){
i <- i+1
strategy <- strategies %>% pull(strategy)
# calculate recency-weighted probability of finding strategy s
c(alphas,betas,beta_map,beta_variance) %<-% get_maggi(strategy)
# store data
beta_maps[i,1:ncol(beta_maps)] <- beta_map
if (save_plots){
# view alphas and betas over time
points(1:length(strategy),beta_map,type="l",col=colours[i])
}
}
if (save_plots){
dev.off()
}
# format the data
data <- data.frame(sub = integer(), ses = integer(), context = integer(), train_type = integer(), transfer = integer(), event = integer(), k1 = numeric(), k2 = numeric(), k3 = numeric(), k4 = numeric(), win = integer())
for (event in 1:length(beta_map)){
win <- which(beta_maps[1:nrow(beta_maps),event] == max(beta_maps[1:nrow(beta_maps),event]))
if (sum(beta_maps[1:nrow(beta_maps),event])==0){win <- NA}
tmp <- data.frame(sid, ses, context, transfer, train_type, event, k1 = beta_maps[1,event], k2 = beta_maps[2,event], k3 = beta_maps[3,event], k4 = beta_maps[4,event], win)
data <- rbind(data,tmp)
}
last_strategy_change <- max(which(diff(data$win)!=0))+1
data <- data %>%
mutate(stable_k4 = case_when(event < last_strategy_change ~ 0, event %in% intersect(which(event >= last_strategy_change), which(win == 4)) ~ 1, .default = NA))
group_data <- rbind(group_data,data)
}
}
}
}
# threshold ---------------------------------------------------------------
results <- group_data %>% group_by(sid,ses,context,train_type,transfer) %>% summarise(nclicks = n(),k4_onset = min(which(stable_k4==1)))
}
write.csv(group_data,file.path('res',paste(paste(exp,'maggi-map',sep='_'),'csv', sep='.')))
write.csv(results,file.path('res',paste(paste(exp,'maggi-k4',sep='_'),'csv', sep='.')))
results_wide <- results %>% filter(ses==1) %>% rename(k4_learn=k4_onset)
results_wide$k4_test <- results %>% filter(ses==3) %>% pull(k4_onset)
View(results_wide)
View(results)
View(results)
if(exp=="exp_lt"){
results <- results %>% filter(sid!=64)
}
results_wide <- results %>% filter(ses==1) %>% rename(k4_learn=k4_onset)
results_wide$k4_test <- results %>% filter(ses==3) %>% pull(k4_onset)
# lydia barnes, march 2024 this script extracts, formats, and summarises data from the 'doors'
# project.
### sources
library(tidyverse)
library(zeallot) #unpack/destructure with %<-%
source(file.path("src", "get_subs.R"))
source(file.path("src", "get_switch.R"))
source(file.path("src", "get_data.R"))
source(file.path("src","get_setting_stability.R"))
source(file.path("src","get_transition_probabilities.R"))
source(file.path("src","get_learned_doors.R"))
### settings
# !you will want to update these settings a lot during piloting, when the task code or the way you
# test changes, or when you test participants on different subsets of the task phases
version <- "study-01" # pilot-data-00 (train and test), pilot-data-01 (learn and train), pilot-data-02 (learn and train, learn phase split into two parts)
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
sess <- c("ses-learn","ses-train","ses-test") # session: 'ses-learn','ses-train','ses-test'. can select one (e.g. ses <- c('ses-learn')) or multiple (e.g. ses <- c('ses-train','ses-test'))
### paths
# !if you open the project thru doors.Rproj, your working directory will automatically be the
# project path
project_path <- getwd()
if (!dir.exists(file.path(project_path, "res"))) {
# check that the results directory exists. if it doesn't, create it.
dir.create(file.path(project_path, "res"))
}
# !you will need to change the data path to match the location of OneDrive on your personal
# computer
data_path <- file.path("/Users/lydiabarnes/OneDrive - UNSW/task switch and transfer/data-sandpit", version)
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
### load an up-to-date list of participants
subs <- get_subs(exp, version)
### extract events from the raw data
# make an empty data frame with all the variables (columns) that we will want
grp_data <- data.frame(
sub = integer(), ses = integer(), subses = integer(), t = integer(), context = integer(), door = integer(),
door_cc = integer(), door_oc = integer(), on = numeric(), off = numeric(),
switch = integer(), train_type = integer(), transfer = integer(), full_transfer_first = integer(),
original_house = integer()
)
# for each subject and session, use the function 'get_data' to load their raw data and attach it to
# our 'grp_data' data frame with one measurement (row) per event (click or hover)
for (sub in subs) {
print(sub)
sid <- as.numeric(substring(sub,5,7))
for (ses in sess) {
train_type <- NA
context_one_doors <- NA
if (exp=="exp_lt" && sub=="sub-64" && ses=="ses-learn"){
print("skipping missing data")
}else{
if (ses == "ses-test") {
train_type <- grp_data %>%
filter(sub == sid, ses == 2) %>%
select(train_type) %>%
unique() %>%
pull()
train_doors <- grp_data %>%
filter(sub==sid,ses==ses,door_cc==1) %>%
select(door,context) %>%
unique()
}
data <- get_data(data_path, exp, sub, ses, train_type, train_doors) # load and format raw data
grp_data <- rbind(grp_data, data) # add to the 'grp_data' data frame so we end up with all subjects and sessions in one spreadsheet
}
}
}
# track whether context-incorrect clicks in the test phase land on doors that were learned in the train phase
if(exp=="exp_lt"){
door_lc <- get_learned_doors(grp_data)
grp_data <- grp_data %>% add_column(door_lc = door_lc, .after="door_oc")
}else{
grp_data <- grp_data %>% mutate(door_lc = c(kronecker(matrix(1, nrow(res), 1), NA)), .after="door_oc")
}
# lydia barnes, march 2024 this script extracts, formats, and summarises data from the 'doors'
# project.
### sources
library(tidyverse)
library(zeallot) #unpack/destructure with %<-%
source(file.path("src", "get_subs.R"))
source(file.path("src", "get_switch.R"))
source(file.path("src", "get_data.R"))
source(file.path("src","get_setting_stability.R"))
source(file.path("src","get_transition_probabilities.R"))
source(file.path("src","get_learned_doors.R"))
### settings
# !you will want to update these settings a lot during piloting, when the task code or the way you
# test changes, or when you test participants on different subsets of the task phases
version <- "study-01" # pilot-data-00 (train and test), pilot-data-01 (learn and train), pilot-data-02 (learn and train, learn phase split into two parts)
exp <- "exp_ts" # experiment: 'exp_ts' (task-switching) or 'exp_lt' (learning transfer)
sess <- c("ses-learn","ses-train","ses-test") # session: 'ses-learn','ses-train','ses-test'. can select one (e.g. ses <- c('ses-learn')) or multiple (e.g. ses <- c('ses-train','ses-test'))
### paths
# !if you open the project thru doors.Rproj, your working directory will automatically be the
# project path
project_path <- getwd()
if (!dir.exists(file.path(project_path, "res"))) {
# check that the results directory exists. if it doesn't, create it.
dir.create(file.path(project_path, "res"))
}
# !you will need to change the data path to match the location of OneDrive on your personal
# computer
data_path <- file.path("/Users/lydiabarnes/OneDrive - UNSW/task switch and transfer/data-sandpit", version)
if (!dir.exists(data_path)) {
stop(paste0(data_path, " does not exist"))
}
### load an up-to-date list of participants
subs <- get_subs(exp, version)
### extract events from the raw data
# make an empty data frame with all the variables (columns) that we will want
grp_data <- data.frame(
sub = integer(), ses = integer(), subses = integer(), t = integer(), context = integer(), door = integer(),
door_cc = integer(), door_oc = integer(), on = numeric(), off = numeric(),
switch = integer(), train_type = integer(), transfer = integer(), full_transfer_first = integer(),
original_house = integer()
)
# for each subject and session, use the function 'get_data' to load their raw data and attach it to
# our 'grp_data' data frame with one measurement (row) per event (click or hover)
for (sub in subs) {
print(sub)
sid <- as.numeric(substring(sub,5,7))
for (ses in sess) {
train_type <- NA
context_one_doors <- NA
if (exp=="exp_lt" && sub=="sub-64" && ses=="ses-learn"){
print("skipping missing data")
}else{
if (ses == "ses-test") {
train_type <- grp_data %>%
filter(sub == sid, ses == 2) %>%
select(train_type) %>%
unique() %>%
pull()
train_doors <- grp_data %>%
filter(sub==sid,ses==ses,door_cc==1) %>%
select(door,context) %>%
unique()
}
data <- get_data(data_path, exp, sub, ses, train_type, train_doors) # load and format raw data
grp_data <- rbind(grp_data, data) # add to the 'grp_data' data frame so we end up with all subjects and sessions in one spreadsheet
}
}
}
# track whether context-incorrect clicks in the test phase land on doors that were learned in the train phase
if(exp=="exp_lt"){
door_lc <- get_learned_doors(grp_data)
grp_data <- grp_data %>% add_column(door_lc = door_lc, .after="door_oc")
}else{
grp_data <- grp_data %>% mutate(door_lc = c(kronecker(matrix(1, nrow(grp_data), 1), NA)), .after="door_oc")
}
# track when they changed context into the correct or other context's door set
select_context <- get_setting_stability(grp_data)
grp_data <- grp_data %>% add_column(select_cc = select_context$s_cc,select_oc = select_context$s_oc, select_oc_late = select_context$s_oc_late, select_total = select_context$s_total, select_cumulative = select_context$s_cumulative,.after="door_lc")
grp_data <- grp_data %>% mutate(door_nc = case_when(door_cc==1 ~ 0, door_oc == 1 ~ 0, .default=1), .after="door_oc")
# save the formatted data
fnl <- file.path(project_path, "res", paste(paste(exp, "evt", sep = "_"), ".csv", sep = ""))
write_csv(grp_data, fnl)
### extract accuracy and response time averages from event data
# by trial
res <- grp_data %>%
group_by(sub, ses, subses, t, context, train_type, transfer, full_transfer_first, original_house) %>%
summarise(
switch = max(switch), n_clicks = n(), n_cc = sum(door_cc), n_oc = sum(door_oc), n_lc = sum(door_lc), n_nc = sum(door_nc),
setting_sticks = select_oc[1],
setting_slips = max(select_oc_late),
context_changes = sum(select_cc)+sum(select_oc),
accuracy = n_cc / n_clicks,
general_errors = n_cc / n_clicks,
setting_errors = n_oc / n_clicks,
learned_setting_errors = n_lc / n_clicks
)
res$context_changes[intersect(which(res$switch==1),which(res$ses==2))] <- res$context_changes[intersect(which(res$switch==1),which(res$ses==2))]-1
rt <- grp_data %>%
group_by(sub, ses, subses, t, context, train_type, transfer) %>%
filter(door_cc == 1) %>%
summarise(rt = min(off)) # time to first correct click offset
res$rt <- rt$rt
res$win <- 4-res$n_clicks >= 0
fnl <- file.path(project_path, "res", paste(paste(exp, "trl", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
# by subject
#   grouping by subsession
res <- res %>%
group_by(sub, ses, subses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
res <- res %>% select(!t)
fnl <- file.path(project_path, "res", paste(paste(exp, "avg-ss", sep = "_"), ".csv", sep = ""))
write_csv(res, fnl)
#   just grouping by session
res <- res %>%
group_by(sub, ses, context, switch, train_type, transfer, full_transfer_first, original_house) %>%
summarise_all(mean)
res <- res %>% ungroup() %>% mutate(transition_probabilities = c(kronecker(matrix(1, nrow(res), 1), NA)))
if(exp=="exp_lt"){
res$transition_probabilities[which(res$ses==2)] <- get_transition_probabilities(grp_data)
}
res <- res %>% select(!subses, !t)
