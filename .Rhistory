# find what doors belonged to this context
doors_cc <- unique(events$door)
# get the shortest path under this algorithm
shortest <- opt_sub$path_weight[1]
### loop through trials, testing whether they used the shortest path, and how much further they travelled
for (tr in unique(events$t)) {
trial <- events %>% filter(t == tr)
# do their clicks match a shortest path?
match <- 0
for (sol in unique(opt_sub$solution)) {
solution <- opt_sub$door[opt_sub$solution == sol]
if (all(solution[1:length(trial$door)] == trial$door)) {
match <- 1
break
}
}
#   if they've selected four doors, compare directly to the shortest path
path <- trial$door # the doors they clicked, in the order they took (inc. re-clicks)
if (length(unique(path)) == 4) {
if (alg == "travelling") {
path <- c(path, path[1])
} # close the loop!
travelled <- 0
for (i in 2:length(path)) {
travelled <- travelled + graph[path[i - 1], path[i]]
}
} else {
#   otherwise, find the most efficient way to end this sequence
unclicked <- doors_cc[!doors_cc %in% path]
paths <- as_tibble(permutations(n = length(unclicked), r = length(unclicked), v = unclicked))
d <- matrix(unlist(path), nrow = 1, byrow = FALSE)
d <- data.frame(d)
d <- do.call("rbind", replicate(nrow(paths), d, simplify = FALSE))
if (alg == "tsp") {
f <- matrix(path[1], nrow = 1, byrow = FALSE)
f <- data.frame(f)
f <- do.call("rbind", replicate(nrow(paths), f, simplify = FALSE))
paths <- cbind(d, paths, f)
} else {
paths <- cbind(d, paths)
}
travelled <- 0
for (i in 1:nrow(paths)) {
this_path <- paths %>%
slice(i) %>%
unlist(use.names = FALSE)
this_travelled <- 0
for (ii in 2:length(this_path)) {
this_travelled <- this_travelled + graph[this_path[ii - 1], this_path[ii]]
}
if (i == 1) {
travelled <- this_travelled
} else {
travelled <- min(c(travelled, this_travelled))
}
}
}
travelled <- round(travelled,4)
shortest <- round(shortest,4)
overshoot <- travelled - shortest
df[nrow(df) + 1, ] <- data.frame(travelled, match, overshoot)
}
return(df)
}
events <- data %>% filter(switch == 0, sub == su, ses == se, context == co, door_cc == 1, subses == ss)
# make the data frame
tmp <- data.frame(sub = integer(), ses = integer(), t = integer(), context = integer(), subses = integer())
for (tr in unique(events$t)) {
tmp[nrow(tmp) + 1, ] <- data.frame(su, se, tr, co, ss)
}
### travelling salesman solutions (return to start)
opt_sub <- opt %>% filter(sub == su, context == co, algorithm == "travelling")
df <- compare_paths(graph, events, opt_sub, "travelling")
df_tsp <- df %>% rename(travelling_match = match, travelling_overshoot = overshoot)
### shortest hamiltonian path (don't return to start)
opt_sub <- opt %>% filter(sub == su, context == co, algorithm == "hamiltonian")
df <- compare_paths(graph, events, opt_sub, "hamiltonian")
df_hp <- df %>% rename(hamiltonian_match = match, hamiltonian_overshoot = overshoot) %>% select(hamiltonian_match,hamiltonian_overshoot)
# stack
tmp <- cbind(tmp, df_tsp, df_hp)
compare_paths <- function(graph, events, opt_sub, alg) {
df <- data.frame(travelled = double(), match = double(), overshoot = double())
# find what doors belonged to this context
doors_cc <- unique(events$door)
# get the shortest path under this algorithm
shortest <- opt_sub$path_weight[1]
### loop through trials, testing whether they used the shortest path, and how much further they travelled
for (tr in unique(events$t)) {
trial <- events %>% filter(t == tr)
# do their clicks match a shortest path?
match <- 0
for (sol in unique(opt_sub$solution)) {
solution <- opt_sub$door[opt_sub$solution == sol]
if (all(solution[1:length(trial$door)] == trial$door)) {
match <- 1
break
}
}
#   if they've selected four doors, compare directly to the shortest path
path <- trial$door # the doors they clicked, in the order they took (inc. re-clicks)
if (length(unique(path)) == 4) {
if (alg == "travelling") {
path <- c(path, path[1])
} # close the loop!
travelled <- 0
for (i in 2:length(path)) {
travelled <- travelled + graph[path[i - 1], path[i]]
}
} else {
#   otherwise, find the most efficient way to end this sequence
unclicked <- doors_cc[!doors_cc %in% path]
paths <- as_tibble(permutations(n = length(unclicked), r = length(unclicked), v = unclicked))
d <- matrix(unlist(path), nrow = 1, byrow = FALSE)
d <- data.frame(d)
d <- do.call("rbind", replicate(nrow(paths), d, simplify = FALSE))
if (alg == "travelling") {
f <- matrix(path[1], nrow = 1, byrow = FALSE)
f <- data.frame(f)
f <- do.call("rbind", replicate(nrow(paths), f, simplify = FALSE))
paths <- cbind(d, paths, f)
} else {
paths <- cbind(d, paths)
}
travelled <- 0
for (i in 1:nrow(paths)) {
this_path <- paths %>%
slice(i) %>%
unlist(use.names = FALSE)
this_travelled <- 0
for (ii in 2:length(this_path)) {
this_travelled <- this_travelled + graph[this_path[ii - 1], this_path[ii]]
}
if (i == 1) {
travelled <- this_travelled
} else {
travelled <- min(c(travelled, this_travelled))
}
}
}
travelled <- round(travelled,4)
shortest <- round(shortest,4)
overshoot <- travelled - shortest
df[nrow(df) + 1, ] <- data.frame(travelled, match, overshoot)
}
return(df)
}
events <- data %>% filter(switch == 0, sub == su, ses == se, context == co, door_cc == 1, subses == ss)
# make the data frame
tmp <- data.frame(sub = integer(), ses = integer(), t = integer(), context = integer(), subses = integer())
for (tr in unique(events$t)) {
tmp[nrow(tmp) + 1, ] <- data.frame(su, se, tr, co, ss)
}
### travelling salesman solutions (return to start)
opt_sub <- opt %>% filter(sub == su, context == co, algorithm == "travelling")
df <- compare_paths(graph, events, opt_sub, "travelling")
df_tsp <- df %>% rename(travelling_match = match, travelling_overshoot = overshoot)
### shortest hamiltonian path (don't return to start)
opt_sub <- opt %>% filter(sub == su, context == co, algorithm == "hamiltonian")
df <- compare_paths(graph, events, opt_sub, "hamiltonian")
df_hp <- df %>% rename(hamiltonian_match = match, hamiltonian_overshoot = overshoot) %>% select(hamiltonian_match,hamiltonian_overshoot)
# stack
tmp <- cbind(tmp, df_tsp, df_hp)
path_match <- rbind(path_match, tmp)
View(path_match)
path_match <- data.frame(
sub = integer(), ses = integer(), t = integer(), context = integer(), subses = integer(), travelled = double(),
travelling_match = double(), travelling_overshoot = double(), hamiltonian_match = double(), hamiltonian_overshoot = double()
)
path_match <- rbind(path_match, tmp)
source("~/Documents/academe/projects/doors/src-stereo/run_stereo.R", echo=TRUE)
events <- data %>% filter(switch == 0, sub == su, ses == se, context == co, subses == ss, door_cc == 1)
# -------------------------------------------------------------------------
# make the full transitions matrix
transition_matrix <- matrix(0, nrow = 16, ncol = 16)
# select a trial
for (tr in unique(events$t)) {
trial <- events %>% filter(t == tr)
# if there's more than one event, record door transitions
if (nrow(trial) > 1) {
for (i in 2:nrow(trial)) {
door <- trial$door[i]
previous <- trial$door[i - 1]
transition_matrix[previous, door] <- transition_matrix[previous,door]+1
}
}
}
colMax <- function(data) sapply(data, max, na.rm = TRUE)
View(transition_matrix)
transition_counts <- colSums(as.matrix(transition_matrix > 0)+0)
transition_counts
transition_counts <- mean(transition_counts[transition_counts != 0])
transition_counts
transition_weights <- colSums(transition_matrix)/colMax(transition_matrix)
transition_weights
colSums(transition_matrix)
colMax(transition_matrix)
sapply(transition_matrix,max,na.rm = TRUE)
sapply?
?sapply
sapply(transition_matrix, max, na.rm = TRUE, simplify = "array")
sapply(data.frame(transition_matrix), max, na.rm = TRUE, simplify = "array")
sapply(data.frame(transition_matrix), max, na.rm = TRUE, simplify = TRUE)
sapply(data.frame(transition_matrix), max, na.rm = TRUE)
data.matrix(sapply(data.frame(transition_matrix), max, na.rm = TRUE))
# lydia barnes created december 2023
library(tidyverse)
library(dplyr)
library(tidyjson)
library(stringr)
library(readr)
library(ggforce)
data_path <- '/Users/lydiabarnes/Documents/academe/data/upPer/behaviour_main'
project_path <- '/Users/lydiabarnes/Documents/academe/projects/upPer/behaviour_main'
date = '20231215b'
source(file.path(project_path,'src','get_files.R'))
files <- get_files()
source(file.path(project_path,'src','get_hits.R'))
source(file.path(project_path,'src','extract.R'))
fnl_u <- file.path(project_path,'results',paste(date,'untimed_t-all.csv',sep = "_"))
fnl_t <- file.path(project_path,'results',paste(date,'timed_t-all.csv',sep = "_"))
fnl_u <- file.path(project_path,'results',paste(date,'untimed_t-all.csv',sep = "_"))
fnl_t <- file.path(project_path,'results',paste(date,'timed_t-all.csv',sep = "_"))
untimed <- read.csv(fnl_u)
date = '20231215'
fnl_u <- file.path(project_path,'results',paste(date,'untimed_t-all.csv',sep = "_"))
fnl_t <- file.path(project_path,'results',paste(date,'timed_t-all.csv',sep = "_"))
untimed <- read.csv(fnl_u)
timed <- read.csv(fnl_t)
project_path <- '/Users/lydiabarnes/Documents/academe/projects/upPer/behaviour_main'
version <- date
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
View(results_u)
h1 <- array(unlist(results_u$h1))
fa1 <- array(unlist(results_u$fa1))
results_u$fa1 <- as.numeric(tweak(fa1))
source(file.path(project_path,'src','tweak.R'))
results_u$fa1 <- as.numeric(tweak(fa1))
tweak <- function(h){
n = length(h)
idx <- which(h == 0.00)
h[idx] <- .5/n
idx <- which(is.nan(h))
h[idx] <- .5/n
return(h)
}
results_u$fa1 <- as.numeric(tweak(fa1))
View(results_u)
tweak <- function(h){
n = length(h)
browser()
idx <- which(h == 0.00)
h[idx] <- .5/n
idx <- which(is.nan(h))
h[idx] <- .5/n
return(h)
}
results_u$fa1 <- as.numeric(tweak(fa1))
ntrials <- results_u %>% summarise(n = count)
ntrials <- results_u %>% summarise(n = count())
ntrials <- results_u %>% summarise(n = n())
View(ntrials)
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
View(results_u)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[1]
ntrials
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
ntrials
View(results_u)
tweak <- function(fa,n){
idx <- which(fa == 0.00)
fa[idx] <- .5/n
idx <- which(is.nan(fa))
fa[idx] <- .5/n
return(fa)
}
fa1 <- array(unlist(results_u$fa1))
results_u$fa1 <- as.numeric(tweak(fa1,ntrials))
results_u$dprime1 <- qnorm(results_u$h1) - qnorm(results_u$fa1) #usually convert hit rate and false alarm rate to zscores before subtracting
fa2 <- array(unlist(results_u$fa2))
results_u$fa2 <- as.numeric(tweak(fa2,ntrials))
results_u$dprime2 <- qnorm(results_u$h2) - qnorm(results_u$fa2)
fa3 <- array(unlist(results_u$fa3))
results_u$fa3 <- as.numeric(tweak(fa3,ntrials))
results_u$dprime3 <- qnorm(results_u$h3) - qnorm(results_u$fa3)
# lydia barnes, june 2024
# adjusts a false-alarm rate of zero or hit rate of one by .5/ntrials
tweak <- function(x,n){
idx <- which(x == 0.00)
x[idx] <- .5/n
idx <- which(is.nan(x))
x[idx] <- .5/n
idx <- which(x == 1.00)
x[idx] <- 1.00 - .5/n
return(x)
}
fa1 <- array(unlist(results_u$fa1))
results_u$fa1 <- as.numeric(tweak(fa1,ntrials))
results_u$dprime1 <- qnorm(results_u$h1) - qnorm(results_u$fa1) #usually convert hit rate and false alarm rate to zscores before subtracting
fa2 <- array(unlist(results_u$fa2))
results_u$fa2 <- as.numeric(tweak(fa2,ntrials))
results_u$dprime2 <- qnorm(results_u$h2) - qnorm(results_u$fa2)
fa3 <- array(unlist(results_u$fa3))
results_u$fa3 <- as.numeric(tweak(fa3,ntrials))
results_u$dprime3 <- qnorm(results_u$h3) - qnorm(results_u$fa3)
results_u <- results_u %>% rowwise() %>% mutate(dprime = mean(c(dprime1,dprime2,dprime3),na.rm=TRUE))
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
results_u$h1 <- as.numeric(tweak(array(unlist(results_u$h1)),ntrials))
results_u$fa1 <- as.numeric(tweak(array(unlist(results_u$fa1)),ntrials))
results_u$dprime1 <- qnorm(results_u$h1) - qnorm(results_u$fa1) #usually convert hit rate and false alarm rate to zscores before subtracting
results_u$h3 <- as.numeric(tweak(array(unlist(results_u$h3)),ntrials))
results_u$fa2 <- as.numeric(tweak(array(unlist(results_u$fa2)),ntrials))
results_u$dprime2 <- qnorm(results_u$h2) - qnorm(results_u$fa2)
results_u$h3 <- as.numeric(tweak(array(unlist(results_u$h3)),ntrials))
results_u$fa3 <- as.numeric(tweak(array(unlist(results_u$fa3)),ntrials))
results_u$dprime3 <- qnorm(results_u$h3) - qnorm(results_u$fa3)
results_u <- results_u %>% rowwise() %>% mutate(dprime = mean(c(dprime1,dprime2,dprime3),na.rm=TRUE))
### summarise
# summarise the self-timed task data
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
results_u$h1 <- as.numeric(tweak(array(unlist(results_u$h1)),ntrials))
results_u$fa1 <- as.numeric(tweak(array(unlist(results_u$fa1)),ntrials))
results_u$dprime1 <- qnorm(results_u$h1) - qnorm(results_u$fa1) #usually convert hit rate and false alarm rate to zscores before subtracting
results_u$h2 <- as.numeric(tweak(array(unlist(results_u$h2)),ntrials))
results_u$fa2 <- as.numeric(tweak(array(unlist(results_u$fa2)),ntrials))
results_u$dprime2 <- qnorm(results_u$h2) - qnorm(results_u$fa2)
results_u$h3 <- as.numeric(tweak(array(unlist(results_u$h3)),ntrials))
results_u$fa3 <- as.numeric(tweak(array(unlist(results_u$fa3)),ntrials))
results_u$dprime3 <- qnorm(results_u$h3) - qnorm(results_u$fa3)
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
test <- results_u %>% select(h1:fa3)
test <- results_u %>% ungroup() %>% select(h1:fa3)
View(test)
function(x){as.numeric(tweak(array(unlist(x)),ntrials))}
y <- function(x){as.numeric(tweak(array(unlist(x)),ntrials))}
test_out <- lapply(test,y)
View(test_out)
test_out <- sapply(test,y)
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
y <- function(x){as.numeric(tweak(array(unlist(x)),ntrials))}
hits_alarms <- results_u %>% ungroup() %>% select(h1:fa3)
results_u$h1:fa3 <- sapply(hits_alarms,y)
# summarise the self-timed task data
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
y <- function(x){as.numeric(tweak(array(unlist(x)),ntrials))}
hits_alarms <- results_u %>% ungroup() %>% select(h1:fa3)
hits_alarms <- sapply(hits_alarms,y)
results_u$h1:fa3 <- hits_alarms
results_u$h1:fa3 <- 1
results_u[,7:12] <- 1
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
y <- function(x){as.numeric(tweak(array(unlist(x)),ntrials))}
hits_alarms <- results_u %>% ungroup() %>% select(h1:fa3)
hits_alarms <- sapply(hits_alarms,y)
results_u[,7:12] <- hits_alarms
results_u[,h1:fa3] <- hits_alarms
results_u <- untimed %>%
group_by(subject,phase,image_type,disambiguated) %>%
summarise(
n = n(),
accuracy = mean(correct),
rt = mean(rt),
h1 = sum(hit1)/(sum(miss1)+sum(hit1)), #when real image was present, how likely were they to respond 'real'?
fa1 = sum(false_alarm1)/(sum(absent1)+sum(false_alarm1)), #when real image was absent, how likely were they to respond 'real'?
h2 = sum(hit2)/(sum(miss2)+sum(hit2)),
fa2 = sum(false_alarm2)/(sum(absent2)+sum(false_alarm2)),
h3 = sum(hit3)/(sum(miss3)+sum(hit3)),
fa3 = sum(false_alarm3)/(sum(absent3)+sum(false_alarm3)),
confidence = mean(confidence)
)
ntrials <- results_u %>% pull(n)
ntrials <- ntrials[[1]]
results_u <- results_u %>% select(!n)
y <- function(x){as.numeric(tweak(array(unlist(x)),ntrials))}
hits_alarms <- results_u %>% ungroup() %>% select(h1:fa3)
hits_alarms <- sapply(hits_alarms,y)
results_u[,7:12] <- hits_alarms
results_u$dprime1 <- qnorm(results_u$h1) - qnorm(results_u$fa1)
results_u$dprime2 <- qnorm(results_u$h2) - qnorm(results_u$fa2)
results_u$dprime3 <- qnorm(results_u$h3) - qnorm(results_u$fa3)
results_u <- results_u %>% rowwise() %>% mutate(dprime = mean(c(dprime1,dprime2,dprime3),na.rm=TRUE))
source(file.path(project_path,'src','format.R'))
untimed <- read.csv(fnl_u)
timed <- read.csv(fnl_t)
format(untimed,timed,project_path,date)
source(file.path(project_path,'src','format.R'))
untimed <- read.csv(fnl_u)
timed <- read.csv(fnl_t)
format(untimed,timed,project_path,date)
